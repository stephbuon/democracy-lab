{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first preprocesses the data: \n",
    "# group the debate titles by date (month, year, decade)\n",
    "# export to txt files? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So it sounds like my assignment should be using dynamic topic modeling to order debate \n",
    "#titles by theme and then figure out where the biggest rises and falls are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd \n",
    "import re\n",
    "\n",
    "from gensim.models import ldaseqmodel\n",
    "from gensim.corpora import Dictionary, bleicorpus\n",
    "from gensim.matutils import hellinger\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "hansard = pd.read_csv('/users/sbuongiorno/hansard_justnine_w_year.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "hansard = hansard.sample(800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_leading_whitespaces(text):\n",
    "     return re.sub(r\"^\\s+\",\"\",text)\n",
    "\n",
    "def make_dir(data, fname): \n",
    "    path = os.getcwd()\n",
    "    current_folder = os.path.basename(path)\n",
    "    target_folder = fname + '_subsets'\n",
    "    \n",
    "    os.makedirs(target_folder, exist_ok=True)\n",
    "    return target_folder\n",
    "\n",
    "\n",
    "def clean_strings(data, keep):\n",
    "    patterns = ['\\[', '\\]', '\\(', '\\)', '—$', '^—', '\\\"', '^ ', '^\\'']#, '—', '\\.']\n",
    "\n",
    "    for pattern in patterns:\n",
    "        regex = re.compile(pattern)\n",
    "        data[keep] = data[keep].str.replace(regex, '')\n",
    "        \n",
    "    #shortword = re.compile(r'\\W*\\b\\w{1,3}\\b')\n",
    "    #data[keep] = data[keep].str.replace(shortword, '')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def preprocess_dtm(data, col_name, keep, drop, start, end, intv, fname):\n",
    "    target_folder = make_dir(data, fname)\n",
    "    \n",
    "    start = start\n",
    "    end = end\n",
    "    \n",
    "    while start <= end:\n",
    "        start = start + intv\n",
    "        \n",
    "        data = data[[col_name, keep]]\n",
    "        subset = data[(data[col_name] >= start - intv) & (data[col_name] <= start - 1)]\n",
    "\n",
    "        if not subset.empty:\n",
    "            subset[keep] = subset[keep].astype(str).str.upper()\n",
    "            \n",
    "            stopwords = '|'.join(['THE', 'AND', 'NAN'])\n",
    "            subset[keep] = subset[keep].str.replace(stopwords, '')\n",
    "\n",
    "            descr = str(subset[col_name].iloc[0])\n",
    "            descr_2 = str(subset[col_name].iloc[-1])\n",
    "            \n",
    "            subset = clean_strings(subset, keep)\n",
    "            subset = subset.drop(columns=[drop])\n",
    "            subset = subset.drop_duplicates()\n",
    "            #if unit = 'tokens':\n",
    "            #subset = subset[keep].str.split()\n",
    "            \n",
    "            time_slice = int(subset.shape[0])\n",
    "            \n",
    "            subset = subset.values.tolist()\n",
    "                        \n",
    "            dict_subset = Dictionary(subset)\n",
    "            \n",
    "            corpus = [dict_subset.doc2bow(s) for s in subset]\n",
    "            \n",
    "            ldaseq = ldaseqmodel.LdaSeqModel(corpus=corpus,\n",
    "                                             id2word=dict_subset, \n",
    "                                             time_slice=[time_slice],\n",
    "                                             num_topics=2)\n",
    "            \n",
    "            #print(subset)\n",
    "            #print(ldaseq.print_topics())\n",
    "        \n",
    "        if start > end:\n",
    "            return ldaseq\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaseq = preprocess_dtm(data=hansard,\n",
    "                        col_name='year', \n",
    "                        keep='debate', \n",
    "                        drop='year', \n",
    "                        start=1800, \n",
    "                        end=1910, \n",
    "                        intv=10, \n",
    "                        fname='hansard_decade')\n",
    "\n",
    "# add unit = phrase or tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('THIRD RESOLUTION.', 0.16037432740034796),\n",
       "  ('NAVY ESTIMATES, 1910–11.', 0.16037432740034796),\n",
       "  ('CIVIL SERVICES  REVENUE DEPARTMENTS ESTIMATES, 1910–11. ',\n",
       "   0.16037432740034796),\n",
       "  ('DEBATE ON  ADDRESS.', 0.16037432740034796),\n",
       "  ('FICE BILL COLLECTION OF INCOME TAX.', 0.10178688038315399),\n",
       "  ('CONSOLIDATED FUND NO. 2 BILL.', 0.051343162003090824),\n",
       "  ('CLAUSE 1. —INCREASE OF NUMBER OF DEVELOPMENT COMMISSIONERS. ',\n",
       "   0.051343162003090824),\n",
       "  ('TOBACCO IMPORT DUTY.', 0.051343162003090824),\n",
       "  ('CLASS II.', 0.051343162003090824),\n",
       "  (\"SECRETARY FOR SCOTL'S OFFICE.\", 0.051343162003090824)]]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topic_times(topic=0) # change in first topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('PARLIAMENTARY FRANCHISE WOMEN BILL', 0.5641679998279904),\n",
       "  ('BUSINESS  HOUSE', 0.24525165509357863),\n",
       "  ('TRAINING COLLEGES  SECONDARY SCHOOLS', 0.19058034507843097)]]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topic_times(topic=1) # change in second topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('BUSINESS  HOUSE', 0.5881063701472296),\n",
       "  ('TRAINING COLLEGES  SECONDARY SCHOOLS', 0.24513861366837908),\n",
       "  ('PARLIAMENTARY FRANCHISE WOMEN BILL', 0.16675501618439137)],\n",
       " [('PARLIAMENTARY FRANCHISE WOMEN BILL', 0.5641679998279904),\n",
       "  ('BUSINESS  HOUSE', 0.24525165509357863),\n",
       "  ('TRAINING COLLEGES  SECONDARY SCHOOLS', 0.19058034507843097)]]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
