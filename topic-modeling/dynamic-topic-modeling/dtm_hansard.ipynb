{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first preprocesses the data: \n",
    "# group the debate titles by date (month, year, decade)\n",
    "# export to txt files? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from gensim.models import ldaseqmodel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "#os.chdir('/users/sbuongiorno/democracy-lab/util/')\n",
    "\n",
    "#from pyfunctions.str_functions import lemmatize_df_text\n",
    "#from pyfunctions.parallelize_operation import parallelize_operation\n",
    "\n",
    "os.chdir('/users/sbuongiorno/hansard-debate-titles/dynamic-topic-modeling/')\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hansard = pd.read_csv('/users/sbuongiorno/hansard_justnine_w_year.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hansard = hansard.rename(columns = {'text': 'sentence'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = pd.read_csv('/users/sbuongiorno/stopwords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_stopwords = stopwords['stop_word'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do I want to lemmatize words before topic modeling? \n",
    "\n",
    "# dtm_gensim_functions.py\n",
    "\n",
    "#def removing_leading_whitespaces(text):\n",
    "#     return re.sub(r\"^\\s+\",\"\", text)\n",
    "\n",
    "# place holder lists didn't do anything, so I will need to add date separation after the fact -- before plotting\n",
    "\n",
    "# maybe I want to add a space instead, and maybe then I want to remove extra white space\n",
    "\n",
    "def clean_strings(data, group):   \n",
    "    patterns = ['\\[', '\\]', '\\(', '\\)', '—$', '^—', '\\\"', '^ ', '^\\'', '—', '\\.', '\\,', '\\?']\n",
    "\n",
    "    for pattern in patterns:\n",
    "        regex = re.compile(pattern)\n",
    "        data[group] = data[group].str.replace(regex, '')\n",
    "        \n",
    "    shortword = re.compile(r'\\W*\\b\\w{1,3}\\b')\n",
    "    data[group] = data[group].str.replace(shortword, '')\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def dtm_dates(data, date_col, group, start, end, intv):\n",
    "    start = start\n",
    "    end = end\n",
    "    \n",
    "    date_exists = []\n",
    "    \n",
    "    while start < end:\n",
    "        data = data[[date_col, group]]\n",
    "        subset = data[(data[date_col] >= start) & (data[date_col] <= start + 9)]\n",
    "        \n",
    "        if not subset.empty:\n",
    "            date_exists.append(1)\n",
    "            \n",
    "        else:\n",
    "            date_exists.append(0)\n",
    "            \n",
    "        start = start + intv\n",
    "    \n",
    "    return date_exists\n",
    "\n",
    "\n",
    "def label_topics(data, date_col, group, start, end, intv, **kwargs):\n",
    "    stopwords_list = kwargs.get('stopwords_list', None) \n",
    "    start = start\n",
    "    end = end\n",
    "    \n",
    "    n = 3\n",
    "    \n",
    "    while start < end:     \n",
    "        count = {}\n",
    "        \n",
    "        data = data[[date_col, group]]\n",
    "        subset = data[(data[date_col] >= start) & (data[date_col] <= start + 9)]\n",
    "        \n",
    "        if not subset.empty:\n",
    "                        \n",
    "            subset[group] = subset[group].astype(str).str.lower()\n",
    "            \n",
    "            subset = clean_strings(subset, group)\n",
    "            \n",
    "            subset[group] = subset[group].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords_list)]))\n",
    "\n",
    "            subset = subset[group].str.split().tolist()\n",
    "            \n",
    "            for ls in subset:\n",
    "                for string in ls:\n",
    "                    if string in count:\n",
    "                        count[string] += 1\n",
    "                    else:\n",
    "                        count[string] = 1\n",
    "                        \n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        start = start + intv\n",
    "        \n",
    "    topic_label_dict = dict(sorted(count.items(), key = itemgetter(1), reverse = True)[:n])\n",
    "\n",
    "    topic_label = list(topic_label_dict.keys())\n",
    "    \n",
    "    return '-'.join(topic_label)\n",
    "    \n",
    "    \n",
    "def dtm_model(data, date_col, topic_model, start, end, intv, num_topics, **kwargs):\n",
    "    stopwords_list = kwargs.get('stopwords_list', None)\n",
    "    \n",
    "    start = start\n",
    "    end = end\n",
    "    \n",
    "    corpus = []\n",
    "    time_slice = []\n",
    "    dict_subset = Dictionary()\n",
    "    \n",
    "    while start < end:\n",
    "        \n",
    "        data = data[[date_col, topic_model]]\n",
    "        subset = data[(data[date_col] >= start) & (data[date_col] <= start + 9)]\n",
    "        \n",
    "        if not subset.empty:\n",
    "            subset[topic_model] = subset[topic_model].astype(str).str.lower()\n",
    "            \n",
    "            subset = clean_strings(subset, topic_model)\n",
    "            subset = subset.drop(columns=[date_col])\n",
    "            \n",
    "            subset = subset.drop_duplicates()\n",
    "            \n",
    "            subset[topic_model] = subset[topic_model].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords_list)]))\n",
    "                \n",
    "            #subset = parallelize_operation(subset, lemmatize_df_text, n_cores)\n",
    "                \n",
    "            subset = subset[topic_model].str.split()       \n",
    "            \n",
    "            current_time_slice = int(subset.shape[0])\n",
    "            time_slice.append(current_time_slice) \n",
    "                        \n",
    "            subset = subset.values.tolist()\n",
    "                        \n",
    "            current_dict_subset = Dictionary(subset)\n",
    "            dict_subset.merge_with(current_dict_subset)\n",
    "\n",
    "            current_corpus = [dict_subset.doc2bow(s) for s in subset]\n",
    "            corpus.extend(current_corpus)\n",
    "\n",
    "        start = start + intv\n",
    "    \n",
    "    ldaseq = ldaseqmodel.LdaSeqModel(corpus=corpus,\n",
    "                                     id2word=dict_subset,\n",
    "                                     time_slice=time_slice,\n",
    "                                     num_topics=num_topics)\n",
    "\n",
    "    return ldaseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaseq = dtm_model(data=hansard,\n",
    "                   date_col='year', \n",
    "                   topic_model='sentence', \n",
    "                   start=1800, \n",
    "                   end=1920,\n",
    "                   intv=10, \n",
    "                   num_topics=2,\n",
    "                   stopwords_list=list_of_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaseq.save('/users/sbuongiorno/hansard-debate-titles/dynamic-topic-modeling/ldaseq_test_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook dtm_hansard.ipynb to script\n",
      "[NbConvertApp] Writing 6754 bytes to dtm_hansard.py\n"
     ]
    }
   ],
   "source": [
    "#!jupyter nbconvert --to script dtm_hansard.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ldaseqmodel.LdaSeqModel.load('/users/sbuongiorno/hansard-debate-titles/dynamic-topic-modeling/ldaseq_test_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('increase', 0.04430505540456826),\n",
       "  ('affairs', 0.04430505414162301),\n",
       "  ('lords', 0.04430505414162301),\n",
       "  ('salaries', 0.04430505414162301),\n",
       "  ('depraved', 0.014098093769162288),\n",
       "  ('feared', 0.009989856640807704),\n",
       "  ('efficient', 0.009989856640807704),\n",
       "  ('leave', 0.009989856640807704),\n",
       "  ('government', 0.009989856640807704),\n",
       "  ('dark', 0.009989856640807704),\n",
       "  ('services', 0.009989856640807704),\n",
       "  ('acceptance', 0.009989856640807704),\n",
       "  ('left', 0.009989856640807704),\n",
       "  ('addressing', 0.009989856640807704),\n",
       "  ('altogether', 0.009989856640807704),\n",
       "  ('augmentation', 0.009989856640807704),\n",
       "  ('captain', 0.009989856640807704),\n",
       "  ('officials', 0.009989856640807704),\n",
       "  ('year', 0.009989856640807704),\n",
       "  ('high', 0.009989856640807704)],\n",
       " [('commission', 0.026534267047512914),\n",
       "  ('worked', 0.01992334523991067),\n",
       "  ('home', 0.019868562401481715),\n",
       "  ('rule', 0.019868562401481715),\n",
       "  ('sunday', 0.019833990512345846),\n",
       "  ('time', 0.012838106275778355),\n",
       "  ('county', 0.009464679881260029),\n",
       "  ('plan', 0.009454102164084004),\n",
       "  ('depraved', 0.007069946490102274),\n",
       "  ('largest', 0.006075639326474157),\n",
       "  ('hoped', 0.006075639326474157),\n",
       "  ('firms', 0.006075639326474157),\n",
       "  ('opinions', 0.006075639326474157),\n",
       "  ('extract', 0.006075639326474157),\n",
       "  ('expressed', 0.006075639326474157),\n",
       "  ('lengthy', 0.006075639326474157),\n",
       "  ('experience', 0.006075639326474157),\n",
       "  ('essential', 0.006075639326474157),\n",
       "  ('allow', 0.006075639326474157),\n",
       "  ('consulted', 0.006075639326474157)]]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=0) # print all topics for a given time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('increase', 0.04430505540456826),\n",
       "  ('affairs', 0.04430505414162301),\n",
       "  ('lords', 0.04430505414162301),\n",
       "  ('salaries', 0.04430505414162301),\n",
       "  ('depraved', 0.014098093769162288),\n",
       "  ('feared', 0.009989856640807704),\n",
       "  ('efficient', 0.009989856640807704),\n",
       "  ('leave', 0.009989856640807704),\n",
       "  ('government', 0.009989856640807704),\n",
       "  ('dark', 0.009989856640807704),\n",
       "  ('services', 0.009989856640807704),\n",
       "  ('acceptance', 0.009989856640807704),\n",
       "  ('left', 0.009989856640807704),\n",
       "  ('addressing', 0.009989856640807704),\n",
       "  ('altogether', 0.009989856640807704),\n",
       "  ('augmentation', 0.009989856640807704),\n",
       "  ('captain', 0.009989856640807704),\n",
       "  ('officials', 0.009989856640807704),\n",
       "  ('year', 0.009989856640807704),\n",
       "  ('high', 0.009989856640807704)],\n",
       " [('increase', 0.04435764798051931),\n",
       "  ('affairs', 0.04435764691520652),\n",
       "  ('lords', 0.04435764691520652),\n",
       "  ('salaries', 0.04435764691520652),\n",
       "  ('depraved', 0.014098812074167306),\n",
       "  ('feared', 0.00999187298040105),\n",
       "  ('efficient', 0.00999187298040105),\n",
       "  ('leave', 0.00999187298040105),\n",
       "  ('government', 0.00999187298040105),\n",
       "  ('dark', 0.00999187298040105),\n",
       "  ('services', 0.00999187298040105),\n",
       "  ('acceptance', 0.00999187298040105),\n",
       "  ('left', 0.00999187298040105),\n",
       "  ('addressing', 0.00999187298040105),\n",
       "  ('altogether', 0.00999187298040105),\n",
       "  ('augmentation', 0.00999187298040105),\n",
       "  ('captain', 0.00999187298040105),\n",
       "  ('officials', 0.00999187298040105),\n",
       "  ('year', 0.00999187298040105),\n",
       "  ('high', 0.00999187298040105)],\n",
       " [('increase', 0.04438822789668621),\n",
       "  ('affairs', 0.044388226880642395),\n",
       "  ('lords', 0.044388226880642395),\n",
       "  ('salaries', 0.044388226880642395),\n",
       "  ('depraved', 0.014091485883707039),\n",
       "  ('feared', 0.009994450731719728),\n",
       "  ('efficient', 0.009994450731719728),\n",
       "  ('leave', 0.009994450731719728),\n",
       "  ('government', 0.009994450731719728),\n",
       "  ('dark', 0.009994450731719728),\n",
       "  ('services', 0.009994450731719728),\n",
       "  ('acceptance', 0.009994450731719728),\n",
       "  ('left', 0.009994450731719728),\n",
       "  ('addressing', 0.009994450731719728),\n",
       "  ('altogether', 0.009994450731719728),\n",
       "  ('augmentation', 0.009994450731719728),\n",
       "  ('captain', 0.009994450731719728),\n",
       "  ('officials', 0.009994450731719728),\n",
       "  ('year', 0.009994450731719728),\n",
       "  ('high', 0.009994450731719728)],\n",
       " [('increase', 0.044404590029072315),\n",
       "  ('affairs', 0.044404589034165394),\n",
       "  ('lords', 0.044404589034165394),\n",
       "  ('salaries', 0.044404589034165394),\n",
       "  ('depraved', 0.014076977688145963),\n",
       "  ('feared', 0.009997235718568167),\n",
       "  ('efficient', 0.009997235718568167),\n",
       "  ('leave', 0.009997235718568167),\n",
       "  ('government', 0.009997235718568167),\n",
       "  ('dark', 0.009997235718568167),\n",
       "  ('services', 0.009997235718568167),\n",
       "  ('acceptance', 0.009997235718568167),\n",
       "  ('left', 0.009997235718568167),\n",
       "  ('addressing', 0.009997235718568167),\n",
       "  ('altogether', 0.009997235718568167),\n",
       "  ('augmentation', 0.009997235718568167),\n",
       "  ('captain', 0.009997235718568167),\n",
       "  ('officials', 0.009997235718568167),\n",
       "  ('year', 0.009997235718568167),\n",
       "  ('high', 0.009997235718568167)],\n",
       " [('increase', 0.044424869958865826),\n",
       "  ('affairs', 0.04442486901650598),\n",
       "  ('lords', 0.04442486901650598),\n",
       "  ('salaries', 0.04442486901650598),\n",
       "  ('depraved', 0.014058243161303106),\n",
       "  ('feared', 0.009999329330702515),\n",
       "  ('efficient', 0.009999329330702515),\n",
       "  ('leave', 0.009999329330702515),\n",
       "  ('government', 0.009999329330702515),\n",
       "  ('dark', 0.009999329330702515),\n",
       "  ('services', 0.009999329330702515),\n",
       "  ('acceptance', 0.009999329330702515),\n",
       "  ('left', 0.009999329330702515),\n",
       "  ('addressing', 0.009999329330702515),\n",
       "  ('altogether', 0.009999329330702515),\n",
       "  ('augmentation', 0.009999329330702515),\n",
       "  ('captain', 0.009999329330702515),\n",
       "  ('officials', 0.009999329330702515),\n",
       "  ('year', 0.009999329330702515),\n",
       "  ('high', 0.009999329330702515)],\n",
       " [('increase', 0.044442576054916916),\n",
       "  ('affairs', 0.044442575331332626),\n",
       "  ('lords', 0.044442575331332626),\n",
       "  ('salaries', 0.044442575331332626),\n",
       "  ('depraved', 0.014041493456407657),\n",
       "  ('feared', 0.010001004968430087),\n",
       "  ('efficient', 0.010001004968430087),\n",
       "  ('leave', 0.010001004968430087),\n",
       "  ('government', 0.010001004968430087),\n",
       "  ('dark', 0.010001004968430087),\n",
       "  ('services', 0.010001004968430087),\n",
       "  ('acceptance', 0.010001004968430087),\n",
       "  ('left', 0.010001004968430087),\n",
       "  ('addressing', 0.010001004968430087),\n",
       "  ('altogether', 0.010001004968430087),\n",
       "  ('augmentation', 0.010001004968430087),\n",
       "  ('captain', 0.010001004968430087),\n",
       "  ('officials', 0.010001004968430087),\n",
       "  ('year', 0.010001004968430087),\n",
       "  ('high', 0.010001004968430087)],\n",
       " [('increase', 0.04446160442309811),\n",
       "  ('affairs', 0.044461603186581794),\n",
       "  ('lords', 0.044461603186581794),\n",
       "  ('salaries', 0.044461603186581794),\n",
       "  ('depraved', 0.014051645712690788),\n",
       "  ('feared', 0.010001785226538685),\n",
       "  ('efficient', 0.010001785226538685),\n",
       "  ('leave', 0.010001785226538685),\n",
       "  ('government', 0.010001785226538685),\n",
       "  ('dark', 0.010001785226538685),\n",
       "  ('services', 0.010001785226538685),\n",
       "  ('acceptance', 0.010001785226538685),\n",
       "  ('left', 0.010001785226538685),\n",
       "  ('addressing', 0.010001785226538685),\n",
       "  ('altogether', 0.010001785226538685),\n",
       "  ('augmentation', 0.010001785226538685),\n",
       "  ('captain', 0.010001785226538685),\n",
       "  ('officials', 0.010001785226538685),\n",
       "  ('year', 0.010001785226538685),\n",
       "  ('high', 0.010001785226538685)],\n",
       " [('increase', 0.04447537531208723),\n",
       "  ('affairs', 0.04447537386729222),\n",
       "  ('lords', 0.04447537386729222),\n",
       "  ('salaries', 0.04447537386729222),\n",
       "  ('depraved', 0.014064059348174729),\n",
       "  ('feared', 0.010002319455466872),\n",
       "  ('efficient', 0.010002319455466872),\n",
       "  ('leave', 0.010002319455466872),\n",
       "  ('government', 0.010002319455466872),\n",
       "  ('dark', 0.010002319455466872),\n",
       "  ('services', 0.010002319455466872),\n",
       "  ('acceptance', 0.010002319455466872),\n",
       "  ('left', 0.010002319455466872),\n",
       "  ('addressing', 0.010002319455466872),\n",
       "  ('altogether', 0.010002319455466872),\n",
       "  ('augmentation', 0.010002319455466872),\n",
       "  ('captain', 0.010002319455466872),\n",
       "  ('officials', 0.010002319455466872),\n",
       "  ('year', 0.010002319455466872),\n",
       "  ('high', 0.010002319455466872)],\n",
       " [('increase', 0.04448451727187591),\n",
       "  ('affairs', 0.04448451610104168),\n",
       "  ('lords', 0.04448451610104168),\n",
       "  ('salaries', 0.04448451610104168),\n",
       "  ('depraved', 0.014072783693615148),\n",
       "  ('feared', 0.010002664222741237),\n",
       "  ('efficient', 0.010002664222741237),\n",
       "  ('leave', 0.010002664222741237),\n",
       "  ('government', 0.010002664222741237),\n",
       "  ('dark', 0.010002664222741237),\n",
       "  ('services', 0.010002664222741237),\n",
       "  ('acceptance', 0.010002664222741237),\n",
       "  ('left', 0.010002664222741237),\n",
       "  ('addressing', 0.010002664222741237),\n",
       "  ('altogether', 0.010002664222741237),\n",
       "  ('augmentation', 0.010002664222741237),\n",
       "  ('captain', 0.010002664222741237),\n",
       "  ('officials', 0.010002664222741237),\n",
       "  ('year', 0.010002664222741237),\n",
       "  ('high', 0.010002664222741237)],\n",
       " [('increase', 0.04449949420551677),\n",
       "  ('affairs', 0.0444994935116459),\n",
       "  ('lords', 0.0444994935116459),\n",
       "  ('salaries', 0.0444994935116459),\n",
       "  ('depraved', 0.014079000239958676),\n",
       "  ('feared', 0.010002296013146889),\n",
       "  ('efficient', 0.010002296013146889),\n",
       "  ('leave', 0.010002296013146889),\n",
       "  ('government', 0.010002296013146889),\n",
       "  ('dark', 0.010002296013146889),\n",
       "  ('services', 0.010002296013146889),\n",
       "  ('acceptance', 0.010002296013146889),\n",
       "  ('left', 0.010002296013146889),\n",
       "  ('addressing', 0.010002296013146889),\n",
       "  ('altogether', 0.010002296013146889),\n",
       "  ('augmentation', 0.010002296013146889),\n",
       "  ('captain', 0.010002296013146889),\n",
       "  ('officials', 0.010002296013146889),\n",
       "  ('year', 0.010002296013146889),\n",
       "  ('high', 0.010002296013146889)]]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topic_times(topic=0) # change over time in first topic, where each list represents the time interval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = label_topics(data = hansard,\n",
    "#                    date_col = 'year', # change to date_col\n",
    "#                    group = 'debate',\n",
    "#                    start = 1800,\n",
    "#                    end = 1910,\n",
    "#                    intv = 10,\n",
    "#                    stopwords_list=list_of_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'indentured-coolies-indian'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ldaseq = LdaSeqModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#t = 0\n",
    "\n",
    "#for i in test:\n",
    "#    if i != 0:\n",
    "#        print(ldaseq.print_topics(time=t))\n",
    "    \n",
    "#    t = t + 1\n",
    "        \n",
    "\n",
    "#t = 0\n",
    "\n",
    "#for i in range(0, len(test)):\n",
    "    #print(test[i])\n",
    "    \n",
    "#    if test[i] != 0:\n",
    "#        print(ldaseq.print_topics(time=t))\n",
    "    \n",
    "#    t = t + 1\n",
    "\n",
    "#    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the length of range -- if item is not 0, topic (then topic + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
