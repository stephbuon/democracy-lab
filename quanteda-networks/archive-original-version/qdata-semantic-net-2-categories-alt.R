#qdata-semantic-net-2-categories.R

# This code produces a two-category semantic net
# (e.g. concerns and nations) from the dictionary-matches
# generated by Quanteda applied to Hansard in 
# quanteda-code-for-app-2.R.

# The code expects to read a df 
# comprised of results1 (term, id_number), results2, 
# cat1 and cat2, typically 'nations' and 'concerns',
# but also conceivably a speaker's name and nations, 
# or a part of a dictionary (property?) and nations.

# it prioritizes cat1 such that it will show interlinkages between
# say, cities and cities, if cat1 is cities, and cities 
# and concerns, if cat2 is concerns, but not concerns
# and concerns 

# it should be rewritten to use a unique id_number per speech
# or debate rather than "debate" which will create
# false positives (e.g. for the "property tax")

# DEVELOPMENT: 
# 1) The command to create pairs1 can easily overheat with data too large.
# It should be rewritten to split df into decades, run each decade separately in a for loop.
# 2) there is no good way to narrow down the number of entities to graph for g21.
# 3) Probably this should be run in advance to spit out static csv's for major targets 
# (city-concern, nation-concern, concern-office, etc.).  Perhaps the graph visualization 
# should also be pre-computed.
# 4) please review the "nonbritain" search for g22


#from quanteda data to map of nations-categories in debate titles
library(foreach)
library(tidyverse)
library(readxl)
library(lubridate)
library(itertools)
library(dplyr)
library(tibble)
library(doParallel)
library(igraph)
library(ggraph)
library(tidygraph)

# source(quanteda-code-for-app-2.R)
#gen_classifier <- gen_classifier()
# 
# target <- "debate"
# target_description <- "debate titles"
# cat1 <- "nations"
# cat2 <- "concern"
# setwd(datadir)
#tidyresults <-  read_csv(paste0("fulldict-", target, "fromquanteda.csv"))
# c1 <- tidyresults %>% left_join(gen_classifier, by = c("term" = "node")) %>%
#   filter(kind == cat1)
# c2 <- tidyresults %>% left_join(gen_classifier, by = c("term" = "node")) %>%
#   filter(kind == cat2) %>%
#   filter(grepl("land", term))
# df <- rbind(c1, c2) %>% rename(sentence_id = document)
# docdate <- hansard %>% select(sentence_id, debate_id, speechdate)
# df <- df %>% left_join(docdate)

#### import results and turn into a network.
# import results and limit to those in classifier

pairs1 <- data.frame() 

parallel <- TRUE
setup_parallel()

if(target == "text"){
pairs1 <- foreach(y1 = 1806:1911, .combine = rbind,
        .packages = c("dplyr", "tidyr")) %dopar% {   # in 1806:1911){
  df1 <- df %>% #filter(year >= 1800+(d1*10)) %>%
     #<= 1809+(d1*10))#
    filter(year == y1) 
terms <- df1 %>%
  distinct(speechdate, sentence_id, term, count) %>%
  #mutate(debate = paste0(speechdate, "-", debate)) %>%
  group_by(sentence_id, term) %>%
  summarize(count = sum(count)) %>%
  ungroup() %>%
  ungroup() 

termsinpairs <- terms %>%
  group_by(sentence_id) %>%
  mutate(numterms = n()) %>%
  ungroup() %>%
  filter(numterms > 1) %>%
  select(-numterms)

# get pairwise counts
  
pairs0 <- termsinpairs %>% 
  # mutate(edgeid = paste0(debate, "-", speechdate)) %>%
  # select(edgeid, term) %>%
  group_by(sentence_id) %>% 
  expand(sentence_id, from = term, to = term) %>% 
  filter(from < to) %>%
  ungroup()

pairs0
}
}

closeAllConnections()

if(target == "debate"){
 
    terms <- df %>%
      distinct(speechdate, debate_id, term, count) %>%
      mutate(count = 1) %>% 
      group_by(debate_id, term) %>%
      summarize(count = sum(count)) %>%
      ungroup() %>%
      ungroup() 
    
    
    termsinpairs <- terms %>%
      group_by(debate_id) %>%
      mutate(numterms = n()) %>%
      ungroup() %>%
      filter(numterms > 1) %>%
      select(-numterms)
    
    # get pairwise counts
    
    pairs0 <- termsinpairs %>% 
      # mutate(edgeid = paste0(debate, "-", speechdate)) %>%
      # select(edgeid, term) %>%
      group_by(debate_id) %>% 
      expand(debate_id, from = term, to = term) %>% 
      filter(from < to) %>%
      ungroup()
    pairs1 <- rbind(pairs0, pairs1)
  
  
}
  
uniqueterms <- df %>%
  group_by(term) %>% 
  sample_n(1) %>% ungroup() %>%
  select(term, kind, geography, empire) 

# create nodes
nodes <- uniqueterms %>% 
  left_join(terms) %>% #rbind(results1, results2) %>% 
 # group_by(term) %>% sample_n(1) %>% ungroup() %>%
  group_by(kind, empire, geography, term) %>%
  summarize(count = sum(count)) %>%
  #rename(node = term) %>%
  arrange(desc(count)) %>% ungroup() %>% ungroup() 

# create edges
edges <- pairs1 %>%
  filter(!is.na(from)) %>%
  filter(!is.na(to)) %>%
  count(from, to) %>%
  rename(weight = n) %>%
  filter(weight > 0) %>%
  filter((from %in% uniqueterms$term)&(to %in% uniqueterms$term))

# retain only the edges where one half minimum is in cat1
classifier1 <- gen_classifier %>% filter(kind == cat1) %>%
  rename(term = node)
classifier2 <- gen_classifier %>% filter(kind == cat2) %>%
  rename(term = node)
edges1 <- edges %>%
  filter(!is.na(from)) %>%
  filter(!is.na(to)) %>%
  filter(from %in% classifier1$term) %>%
  filter(to %in% classifier2$term)
edges2 <- edges %>%
  filter(!is.na(from)) %>%
  filter(!is.na(to)) %>%
  filter(from %in% classifier2$term) %>%
  filter(to %in% classifier1$term) 
edges <- rbind(edges1, edges2)

# count connections
connections <- edges %>%
  group_by(from) %>%
  summarize(connections = n(), total_weight = sum(weight)) %>%
  rename(node = from)

# retain only the nodes that are in edge pairs
nodes <- nodes %>% rename(node = term) %>%
  filter((node %in% edges$from)|(node %in% edges$to))

nodes <- nodes %>% left_join(connections) %>%
  filter(connections > 0) %>%
  filter(total_weight > 0)

# only the nodes that are in edge pairs
nodes <- nodes %>% filter((node %in% edges$from)|(node %in% edges$to))%>%
  arrange(desc(count)) %>%
  filter(!is.na(node)) %>%
  filter(count > 0)  %>%
  mutate(id = row_number())

# add id numbers to nodes
nodes <- nodes %>%
  mutate(id = row_number()) 

# match edges with names of nodes
edges <- edges %>%
  left_join(nodes, by=c("from" = "node")) %>%
  rename(from = id, from_name = from) %>%
  left_join(nodes, by=c("to" = "node")) %>%
  rename(to = id, to_name = to) %>%
  select(from, to, from_name, to_name, weight) %>%
  filter(!is.na(from)) %>%
  filter(!is.na(to)) 

# putin the proper order
edges <- edges %>% 
  mutate(from = as.integer(from)) %>%
  mutate(to = as.integer(to)) %>% 
  select(to, from, everything())
nodes <- nodes %>% select(id, node, everything()) %>%
  mutate(id = as.integer(id)) 

# save those files because generating them takes forever
setwd("~/projects/data")
write_csv(edges, paste0(cat1, "-", cat2, "-", target, "-edges.csv"))
write_csv(nodes, paste0(cat1, "-", cat2, "-", target, "-nodes.csv"))

# make network
ig1 <- graph_from_data_frame(d = edges, vertices = nodes, directed = FALSE)
tidygraph1 <- tbl_graph(nodes = nodes, edges = edges, directed = FALSE)

tidygraph1 <- tidygraph1 %>% bind_nodes(nodes)
tidygraph1
