{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_043.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_044.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_045.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_046.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_047.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_048.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_049.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_050.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_051.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_052.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_053.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_054.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_055.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_056.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_057.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_058.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_059.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_060.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_061.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_062.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_063.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_064.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_065.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_066.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_067.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_068.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_069.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_070.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_071.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_072.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_073.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_074.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_075.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_076.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_077.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_078.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_079.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_080.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_081.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_082.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_083.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_084.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_085.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_086.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_087.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_088.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_089.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_090.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_091.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_092.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_093.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_094.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_095.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_096.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_097.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_098.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_099.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_100.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_101.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_102.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_103.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_104.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_105.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_106.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_107.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_108.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_109.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_110.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_111.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_043.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_044.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_045.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_046.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_047.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_048.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_049.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_050.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_051.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_052.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_053.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_054.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_055.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_056.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_057.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_058.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_059.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_060.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_061.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_062.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_063.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_064.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_065.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_066.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_067.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_068.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_069.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_070.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_071.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_072.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_073.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_074.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_075.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_076.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_077.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_078.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_079.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_080.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_081.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_082.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_083.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_084.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_085.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_086.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_087.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_088.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_089.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_090.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_091.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_092.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_093.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_094.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_095.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_096.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_097.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_098.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_099.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_100.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_101.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_102.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_103.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_104.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_105.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_106.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_107.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_108.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_109.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_110.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_111.txt...\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "def read_speeches():\n",
    "    all_speech_files = glob.glob('/scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_*.txt')\n",
    "    CONGRESS_MIN_THRESHOLD = 1\n",
    "    CONGRESS_MAX_THRESHOLD = 115\n",
    "    \n",
    "    speech_files = []\n",
    "    \n",
    "    for fn in all_speech_files:\n",
    "        number = int(fn.rsplit('_', 1)[-1].split('.')[0])\n",
    "        \n",
    "        if CONGRESS_MIN_THRESHOLD <= number <= CONGRESS_MAX_THRESHOLD:\n",
    "            speech_files.append(fn)\n",
    "            speech_files.sort()\n",
    "    return speech_files\n",
    "\n",
    "def read_descriptions():\n",
    "    all_description_files = glob.glob('/scratch/group/oit_research_data/stanford_congress/hein-bound/descr_*.txt')\n",
    "    CONGRESS_MIN_THRESHOLD = 1\n",
    "    CONGRESS_MAX_THRESHOLD = 115\n",
    "    \n",
    "    description_files = []\n",
    "    \n",
    "    for fn in all_description_files:\n",
    "        number = int(fn.rsplit('_', 1)[-1].split('.')[0])\n",
    "        \n",
    "        if CONGRESS_MIN_THRESHOLD <= number <= CONGRESS_MAX_THRESHOLD:\n",
    "            description_files.append(fn)\n",
    "            description_files.sort()\n",
    "    return description_files\n",
    "        \n",
    "def reader(fn):\n",
    "    print(f'Reading {fn}...')\n",
    "    return pd.read_csv(fn, sep='|', encoding=\"ISO-8859-1\", error_bad_lines=False, warn_bad_lines=False, quoting=csv.QUOTE_NONE)\n",
    "\n",
    "def clean_data(all_data):\n",
    "    all_data = all_data.drop(['chamber', 'speech_id', 'number_within_file', 'speaker', 'first_name'], 1)\n",
    "    all_data = all_data.drop(['last_name', 'state', 'gender', 'line_start', 'line_end', 'file', 'char_count', 'word_count'], 1)\n",
    "    all_data['date']=pd.to_datetime(all_data['date'],format='%Y%m%d')\n",
    "    all_data['year'] = pd.to_datetime(all_data['date']).dt.year\n",
    "    all_data['5yrperiod'] = np.floor(all_data['year'] / 5) * 5 # round each year to the nearest 5 -- by dividing by 5 and \"flooring\" to the lowest integer\n",
    "    all_data = all_data.drop(['date', '5yrperiod'], 1)\n",
    "    all_data['index'] = np.arange(len(all_data)) # create an 'index' column\n",
    "    return all_data\n",
    "    \n",
    "def import_congressional_data(*args, **kwargs):\n",
    "    cd = kwargs.get('clean_data', None)\n",
    "    speech_files = read_speeches()\n",
    "    description_files = read_descriptions()\n",
    "    \n",
    "    speeches_df = pd.concat((reader(fn) for fn in speech_files))\n",
    "    speeches_df.dropna(how='any', inplace=True)\n",
    "    \n",
    "    description_df = pd.concat((reader(fn) for fn in description_files))\n",
    "    \n",
    "    all_data = pd.merge(speeches_df, description_df, on = 'speech_id')\n",
    "    all_data.fillna(0, inplace=True)\n",
    "    \n",
    "    if cd == True:\n",
    "        all_data = clean_data(all_data)\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "congressional_data = import_congressional_data(clean_data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "from varname import nameof\n",
    "\n",
    "def set_dir(data): \n",
    "    path = os.getcwd()\n",
    "    current_folder = os.path.basename(path)\n",
    "    target_folder = nameof(data) + '_subsets'\n",
    "\n",
    "    if current_folder != target_folder:\n",
    "        os.makedirs(target_folder)\n",
    "        os.chdir(target_folder)\n",
    "        \n",
    "def interval_subset(data, col_name, start, end, intv):\n",
    "    set_dir(data)\n",
    "    \n",
    "    start = start\n",
    "    end = end\n",
    "\n",
    "    while start <= end:\n",
    "        start = start + intv\n",
    "        subset = data[(data[col_name] >= start - intv) & (data[col_name] <= start - 1)]\n",
    "        \n",
    "        descr = str(subset[col_name].iloc[0])\n",
    "        descr_2 = str(subset[col_name]. iloc[-1])\n",
    "        \n",
    "        file_name = \"stanford_congressional_records_\" + descr + \"_\" + descr_2\n",
    "        \n",
    "        subset.to_csv(file_name + \".csv\", index = False)\n",
    "        \n",
    "interval_subset(congressional_data, 'year', 1870, 2010, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "from multiprocessing import Process, Queue, cpu_count, Pool\n",
    "\n",
    "n = 1\n",
    "\n",
    "def parallelize_operation(df, function, n_cores = n):\n",
    "    split_df = np.array_split(df, n_cores)\n",
    "    pool = Pool(n)\n",
    "    df = pd.concat(pool.map(function, split_df))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(df):\n",
    "    split_rule = r\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s\"\n",
    "    \n",
    "    df['speech'] = df['speech'].apply(lambda x: re.split(split_rule, x))\n",
    "    \n",
    "    df = df.explode('speech')\n",
    "    df.reset_index()\n",
    "    df.rename(columns = {'speech': 'sentence'}, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The gensim Word2Vec model does not expect strings as its text examples (sentences), \n",
    "# but lists-of-tokens. Thus, it's up to your code to tokenize your text, \n",
    "# before passing it to Word2Vec. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parallelize_operation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-59b66befaefe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mexport_congressional_gensim_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_subsets/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-59b66befaefe>\u001b[0m in \u001b[0;36mexport_congressional_gensim_models\u001b[0;34m(dir_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mimported_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0msentences_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallelize_operation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimported_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0msentences_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentences_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parallelize_operation' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import gensim\n",
    "\n",
    "def export_congressional_gensim_models(dir_path):\n",
    "    file_names = []\n",
    "    cycle = 0\n",
    "    \n",
    "    for fname in os.listdir(dir_path):\n",
    "        file_names.append(fname)\n",
    "        \n",
    "    for fname in file_names:\n",
    "        cycle = cycle + 1\n",
    "        \n",
    "        imported_data = pd.read_csv(dir_path + fname)\n",
    "        \n",
    "        sentences_df = parallelize_operation(imported_data, split_sentences)\n",
    "        \n",
    "        sentences_df['sentence'] = sentences_df['sentence'].str.split()\n",
    "        \n",
    "        period_model = gensim.models.Word2Vec(sentences = sentences_df['sentence'],\n",
    "                                             workers = n, \n",
    "                                             min_count = 20, # remove words stated less than 20 times\n",
    "                                             size = 100) # size of neuralnet layers; default is 100 - go higher for larger corpora \n",
    "        \n",
    "        extention_position = fname.index('.')\n",
    "        fname = fname[0:extention_position]\n",
    "        \n",
    "        #period_model.save(add somethign about period + '_model')\n",
    "        \n",
    "        if cycle == 1:\n",
    "            congress_model = period_model\n",
    "        else:\n",
    "            congress_model.build_vocab(sentences_df['sentence'], update = True)\n",
    "            congress_model.train(sentences_df['sentence'], total_examples = period_model.corpus_count, epochs = period_model.epochs)\n",
    "            \n",
    "        congress_model.save(fname + '_model')\n",
    "                      \n",
    "\n",
    "export_congressional_gensim_models('data_subsets/')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_model = gensim.models.Word2Vec.load('stanford_congressional_records_1873_1874_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Google news vectors\n",
    "#word2vec_path = \"path_to_the_vectors/GoogleNews-vectors-negative300.bin\"\n",
    "#word2vec = gensim.models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "\n",
    "congress_model = gensim.models.Word2Vec.load('stanford_congressional_records_1873_1874_model')# contains the list of all unique words in pre-trained word2vec vectors\n",
    "congress_w2v_vocabulary = congress_model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'of',\n",
       " 'to',\n",
       " 'and',\n",
       " 'that',\n",
       " 'I',\n",
       " 'in',\n",
       " 'a',\n",
       " 'is',\n",
       " 'it',\n",
       " 'be',\n",
       " 'for',\n",
       " 'this',\n",
       " 'not',\n",
       " 'as',\n",
       " 'by',\n",
       " 'have',\n",
       " 'was',\n",
       " 'from',\n",
       " 'on',\n",
       " 'The',\n",
       " 'which',\n",
       " 'will',\n",
       " 'or',\n",
       " 'at']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "congress_model.wv.index2word[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15327"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(congress_model.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2137219 ,  1.3901031 ,  1.6810625 , ...,  0.49358177,\n",
       "        -0.534212  ,  0.26035666],\n",
       "       [-0.33640045,  0.0874925 ,  0.90505594, ...,  1.7964767 ,\n",
       "         0.469082  , -0.7950482 ],\n",
       "       [-0.11258058,  0.15636025,  1.1120806 , ...,  0.12656668,\n",
       "        -0.36181334, -1.1143477 ],\n",
       "       ...,\n",
       "       [ 0.07897078,  0.00347791,  0.02401185, ..., -0.08176875,\n",
       "        -0.10715071,  0.03626795],\n",
       "       [-0.0440694 , -0.06141869,  0.22473088, ..., -0.05709316,\n",
       "        -0.03517441, -0.05756548],\n",
       "       [-0.03267128, -0.10327776,  0.15210785, ..., -0.01559925,\n",
       "         0.08148099,  0.15885909]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "congress_model.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "congress_model.wv.index2word[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.12580575e-01,  1.56360254e-01,  1.11208057e+00, -1.63694394e+00,\n",
       "       -1.96732950e+00, -9.60842311e-01,  2.29880214e+00, -2.83676028e+00,\n",
       "       -1.08457066e-01,  2.01339412e+00,  5.86272538e-01,  1.07936954e+00,\n",
       "        6.83029294e-02, -3.49307925e-01,  6.25689387e-01, -1.29493311e-01,\n",
       "       -5.87438643e-01, -3.05765662e-02,  1.52911568e+00, -7.10536778e-01,\n",
       "       -1.39310700e-03, -1.02884495e+00, -2.01690340e+00,  1.61613047e-01,\n",
       "       -3.70174587e-01, -8.63505006e-01, -4.49686497e-01,  1.22544158e+00,\n",
       "        3.75140369e-01,  9.08234239e-01,  2.79250693e+00,  2.99032950e+00,\n",
       "       -1.03324664e+00,  1.56622362e+00, -6.45567298e-01, -1.08611798e+00,\n",
       "        3.35500926e-01, -1.13525748e+00,  6.65919900e-01, -1.99482679e-01,\n",
       "       -7.95930326e-01, -1.40282226e+00, -4.30072755e-01,  4.89553243e-01,\n",
       "       -1.32687807e+00, -1.02504277e+00,  8.35403919e-01,  4.09150362e-01,\n",
       "        1.36140645e+00, -5.99500835e-01, -2.03080368e+00, -1.65794754e+00,\n",
       "       -1.89322144e-01,  2.20010951e-01,  1.15869153e+00,  9.64737236e-02,\n",
       "        4.75370735e-01, -3.41420412e-01, -6.01797402e-01,  4.81274128e-02,\n",
       "        1.09276783e+00, -1.39974940e+00, -7.54435539e-01, -2.01484129e-01,\n",
       "       -1.84561944e+00, -2.00370622e+00,  1.32922196e+00,  7.42109939e-02,\n",
       "        4.22180414e-01, -3.62107247e-01,  1.51609349e+00,  2.59027147e+00,\n",
       "       -9.26008165e-01,  5.78726768e-01,  2.62810022e-01, -3.08296144e-01,\n",
       "       -8.53217661e-01, -6.18778229e-01,  1.07858634e+00,  2.18420649e+00,\n",
       "       -9.41531897e-01, -8.42053592e-01, -6.11193836e-01,  3.58833432e+00,\n",
       "        1.07112789e+00,  2.37837529e+00, -1.23203290e+00, -5.27988791e-01,\n",
       "        3.35085928e-01,  1.95016146e-01, -9.39624786e-01, -3.98658693e-01,\n",
       "        1.19543493e+00, -1.04928780e+00,  1.09813547e+00, -1.39758801e+00,\n",
       "        4.20003295e-01,  1.26566678e-01, -3.61813337e-01, -1.11434770e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "congress_model.wv['to']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4981839 , -0.07244259, -0.30060878, -1.3876089 , -0.7268536 ,\n",
       "        0.2225371 ,  1.3775698 ,  0.0778371 , -1.0745714 ,  0.70276153,\n",
       "        0.08910023, -0.6716979 , -0.37361118, -0.2846855 ,  0.66448456,\n",
       "        0.3170037 , -0.07228577,  1.2633101 ,  0.35974845, -0.10054018,\n",
       "        0.69000363, -0.03926645, -2.575601  ,  0.06809434, -0.78677446,\n",
       "       -2.218929  , -0.24234462,  0.69691366, -0.17579308,  0.90760595,\n",
       "        0.215567  ,  1.2573235 ,  0.57957834, -0.01310704, -0.22670114,\n",
       "       -1.0446719 , -0.44389293,  0.35116285, -0.34281754, -0.5387338 ,\n",
       "       -0.79898363, -2.0082116 ,  0.9730359 , -0.45276877, -0.7648684 ,\n",
       "       -0.9282157 ,  0.81879985,  0.15924817,  1.2325851 ,  0.7370203 ,\n",
       "        0.75480956,  0.11558668,  0.08720962,  0.0324798 ,  0.94672304,\n",
       "       -1.1605217 , -0.82023114,  1.3042344 ,  1.7554764 , -0.71666425,\n",
       "       -0.34761587, -1.6350881 ,  0.80026555, -0.1075739 ,  0.43415645,\n",
       "       -0.44709942,  0.46373656,  0.0563006 , -0.2595159 , -0.3627512 ,\n",
       "       -0.83575004,  0.14050612, -0.05264447, -0.0371356 ,  0.12846692,\n",
       "       -0.03998097,  0.02017949, -0.0643708 ,  0.95803833,  0.95547444,\n",
       "       -0.53404456, -0.6916462 , -1.4408175 ,  1.0746136 , -1.1509581 ,\n",
       "        0.4649476 , -0.55425733, -0.4118903 , -0.57692647,  0.49584338,\n",
       "       -0.06854404, -0.17112704, -1.0939529 ,  0.06521719,  0.319178  ,\n",
       "       -0.8939102 , -0.37195823,  0.66222286, -0.00623346, -0.7568716 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "congress_model.wv.vectors[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 1.0),\n",
       " ('lawyer', 0.784612774848938),\n",
       " ('mai', 0.7743773460388184),\n",
       " ('merchant', 0.7623230218887329),\n",
       " ('mian', 0.7392277717590332),\n",
       " ('soldier', 0.7370642423629761),\n",
       " ('mani', 0.7255149483680725),\n",
       " ('man.', 0.7229173183441162),\n",
       " ('witness', 0.7200114727020264),\n",
       " ('citizen', 0.7081575393676758)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "man_vector = congress_model.wv['man']\n",
    "congress_model.wv.similar_by_vector(man_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 1.0),\n",
       " ('mau', 0.7833964228630066),\n",
       " ('citizen', 0.7581619620323181),\n",
       " ('soldier', 0.7527076601982117),\n",
       " ('nian', 0.7463874816894531),\n",
       " ('man.', 0.7352272868156433),\n",
       " ('child', 0.7283610105514526),\n",
       " ('mian', 0.7250927090644836),\n",
       " ('foreigner', 0.7204998731613159),\n",
       " ('nan', 0.7189040184020996)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "woman_vector = congress_model.wv['woman']\n",
    "congress_model.wv.similar_by_vector(woman_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('individual', 1.0),\n",
       " ('honest', 0.6170173287391663),\n",
       " ('creditor', 0.6117383241653442),\n",
       " ('individual.', 0.607198178768158),\n",
       " ('superior', 0.5966612100601196),\n",
       " ('fraudulent', 0.5930872559547424),\n",
       " ('citizen.', 0.5888493061065674),\n",
       " ('society', 0.5841152667999268),\n",
       " ('mans', 0.5802187919616699),\n",
       " ('equality', 0.5768246054649353)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_vector = congress_model.wv['individual']\n",
    "congress_model.wv.similar_by_vector(individual_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('soldier', 1.0),\n",
       " ('mian', 0.7534946799278259),\n",
       " ('woman', 0.7527076005935669),\n",
       " ('merchant', 0.7440078258514404),\n",
       " ('pensioner', 0.7385962009429932),\n",
       " ('man', 0.7370642423629761),\n",
       " ('nian', 0.720649003982544),\n",
       " ('master', 0.7148724794387817),\n",
       " ('soldier.', 0.7008633017539978),\n",
       " ('captain', 0.7007896304130554)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soldier_vector = congress_model.wv['soldier']\n",
    "congress_model.wv.similar_by_vector(soldier_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.629509"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "congress_model.wv.similarity('women', 'men')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('children', 0.7644491195678711),\n",
       " ('merchants', 0.7066177129745483),\n",
       " ('rich', 0.6883387565612793),\n",
       " ('children.', 0.6830962896347046),\n",
       " ('colored', 0.6641597747802734),\n",
       " ('soldiers', 0.6595255136489868),\n",
       " ('wealthy', 0.6543371677398682),\n",
       " ('destitute', 0.6537994742393494),\n",
       " ('struggling', 0.6519593000411987),\n",
       " ('poor', 0.6401433348655701),\n",
       " ('traders', 0.6373857259750366),\n",
       " ('farmers', 0.6362103223800659),\n",
       " ('noble', 0.6332833766937256),\n",
       " ('capitalists', 0.6331146955490112),\n",
       " ('men', 0.6295090913772583),\n",
       " ('white', 0.6290037631988525),\n",
       " ('widows', 0.6285388469696045),\n",
       " ('skilled', 0.6273373365402222),\n",
       " ('brave', 0.6266660690307617),\n",
       " ('women.', 0.6257854104042053),\n",
       " ('fields', 0.6237730979919434),\n",
       " ('mechanics', 0.6204156279563904),\n",
       " ('bankers', 0.6146213412284851),\n",
       " ('orphans', 0.6089208722114563),\n",
       " ('families', 0.6071287393569946),\n",
       " ('laborers', 0.6053229570388794),\n",
       " ('black', 0.6006523370742798),\n",
       " ('bread', 0.6006162166595459),\n",
       " ('men.', 0.599524736404419),\n",
       " ('patriotic', 0.5988192558288574),\n",
       " ('habits', 0.5974220633506775),\n",
       " ('pursuits', 0.5959031581878662),\n",
       " ('miners', 0.5947861671447754),\n",
       " ('soldiers.', 0.5942983031272888),\n",
       " ('thousands', 0.5917192697525024),\n",
       " ('boys', 0.5890973806381226),\n",
       " ('trained', 0.5888816714286804),\n",
       " ('poor.', 0.5879998207092285),\n",
       " ('starving', 0.5873784422874451),\n",
       " ('race', 0.5846278667449951),\n",
       " ('agriculturists', 0.5846108794212341),\n",
       " ('nen', 0.5842410326004028),\n",
       " ('culture', 0.5802558064460754),\n",
       " ('themselves', 0.5800082683563232),\n",
       " ('brains', 0.5794540643692017),\n",
       " ('professional', 0.5793476700782776),\n",
       " ('masters', 0.5777071118354797),\n",
       " ('whites', 0.5751538872718811),\n",
       " ('citizens.', 0.5741652250289917),\n",
       " ('sailors.', 0.5740913152694702)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "congress_model.wv.most_similar(\"women\", topn = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('men.', 0.7377591729164124),\n",
       " ('lawyers', 0.6918026208877563),\n",
       " ('persons', 0.6915714144706726),\n",
       " ('people', 0.6704407930374146),\n",
       " ('merchants', 0.6628286242485046),\n",
       " ('gentlemen', 0.6529461145401001),\n",
       " ('Men', 0.6475223302841187),\n",
       " ('ones', 0.6338933110237122),\n",
       " ('women', 0.6295089721679688),\n",
       " ('parties', 0.6241623163223267),\n",
       " ('nen', 0.6230642795562744),\n",
       " ('farmers', 0.6145846843719482),\n",
       " ('capitalists', 0.6073158383369446),\n",
       " ('others', 0.6071662902832031),\n",
       " ('claimants', 0.606265664100647),\n",
       " ('children', 0.605920672416687),\n",
       " ('foreigners', 0.6052873134613037),\n",
       " ('soldiers', 0.5934457778930664),\n",
       " ('ladies', 0.5914616584777832),\n",
       " ('statesmen', 0.5890417695045471),\n",
       " ('witnesses', 0.5890220403671265),\n",
       " ('politicians', 0.5853266716003418),\n",
       " ('mcn', 0.584814190864563),\n",
       " ('laborers', 0.5819270610809326),\n",
       " ('boys', 0.569283127784729),\n",
       " ('man', 0.5680898427963257),\n",
       " ('bankers', 0.5622221827507019),\n",
       " ('officers', 0.5527613162994385),\n",
       " ('Indians', 0.5470938682556152),\n",
       " ('negroes', 0.5468682050704956),\n",
       " ('mon', 0.5464656949043274),\n",
       " ('meu', 0.5446764230728149),\n",
       " ('mechanics', 0.539929211139679),\n",
       " ('individuals', 0.5364984273910522),\n",
       " ('families', 0.5340605974197388),\n",
       " ('mei', 0.5315458178520203),\n",
       " ('mn', 0.5283561944961548),\n",
       " ('pilots', 0.5283349752426147),\n",
       " ('miners', 0.5266439318656921),\n",
       " ('struggling', 0.5257346034049988),\n",
       " ('positions', 0.5250624418258667),\n",
       " ('traders', 0.5240505337715149),\n",
       " ('skilled', 0.523693323135376),\n",
       " ('community', 0.5225451588630676),\n",
       " ('printers', 0.5223860740661621),\n",
       " ('republicans', 0.5173519849777222),\n",
       " ('officials', 0.5146838426589966),\n",
       " ('workmen', 0.5143836736679077),\n",
       " ('whites', 0.5143789052963257),\n",
       " ('inen', 0.5126652121543884)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "congress_model.wv.most_similar(\"men\", topn = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 0.9883699417114258),\n",
       " ('lawyer', 0.7484763264656067),\n",
       " ('mai', 0.7310010194778442),\n",
       " ('merchant', 0.727809727191925),\n",
       " ('witness', 0.6992734670639038),\n",
       " ('mian', 0.6851624250411987),\n",
       " ('mani', 0.6778616905212402),\n",
       " ('soldier', 0.6769345998764038),\n",
       " ('person', 0.6657634973526001),\n",
       " ('man.', 0.6645764112472534),\n",
       " ('mal', 0.6608470678329468),\n",
       " ('farmer', 0.6439114809036255),\n",
       " ('citizen', 0.6430673599243164),\n",
       " ('nian', 0.6202700138092041),\n",
       " ('mans', 0.6109440326690674),\n",
       " ('mau', 0.6074048280715942),\n",
       " ('creditor', 0.5955703258514404),\n",
       " ('foreigner', 0.5867884159088135),\n",
       " ('manufacturer', 0.5841833353042603),\n",
       " ('claimant', 0.5834363698959351),\n",
       " ('officer', 0.5812118053436279),\n",
       " ('party', 0.5800226926803589),\n",
       " ('everybody', 0.5799200534820557),\n",
       " ('child', 0.5793112516403198),\n",
       " ('contractor', 0.5698662996292114),\n",
       " ('anybody', 0.5691004991531372),\n",
       " ('woman', 0.5684463977813721),\n",
       " ('men', 0.5620081424713135),\n",
       " ('importer', 0.559678316116333),\n",
       " ('inventor', 0.552960216999054),\n",
       " ('banker', 0.5415834188461304),\n",
       " ('member', 0.538849949836731),\n",
       " ('debtor', 0.5284122228622437),\n",
       " ('he', 0.5271936655044556),\n",
       " ('nan', 0.5257285237312317),\n",
       " ('inan', 0.5223026871681213),\n",
       " ('lady', 0.5213466882705688),\n",
       " ('race', 0.5204880237579346),\n",
       " ('settler', 0.5193619728088379),\n",
       " ('laborer', 0.5187427997589111)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = congress_model.wv['man'] - congress_model.wv['woman']\n",
    "congress_model.wv.similar_by_vector(diff, topn=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Whereas', 0.4274500608444214),\n",
       " ('limiting', 0.41570499539375305),\n",
       " ('numbered', 0.41557809710502625),\n",
       " ('instructing', 0.4072474241256714),\n",
       " ('following', 0.4035813808441162),\n",
       " ('adopted:', 0.3961528539657593),\n",
       " ('regulating', 0.39190608263015747),\n",
       " ('thatthe', 0.3797934949398041),\n",
       " ('Tite', 0.3781622052192688),\n",
       " ('joint', 0.3772182762622833),\n",
       " ('revised', 0.37709760665893555),\n",
       " ('tse', 0.37491974234580994),\n",
       " ('thie', 0.37036949396133423),\n",
       " ('bythe', 0.3683358430862427),\n",
       " ('Tile', 0.36373409628868103),\n",
       " ('recommend', 0.3621600866317749),\n",
       " ('thme', 0.35904407501220703),\n",
       " ('concurrent', 0.35872596502304077),\n",
       " ('approved', 0.35697197914123535),\n",
       " ('construing', 0.3568660318851471),\n",
       " ('directing', 0.35644006729125977),\n",
       " ('By', 0.3561759889125824),\n",
       " ('thc', 0.3554948568344116),\n",
       " ('relating', 0.35503607988357544),\n",
       " ('refers.', 0.3539797365665436),\n",
       " ('embraced', 0.3507007360458374),\n",
       " ('changing', 0.34920966625213623),\n",
       " ('askc', 0.3470391631126404),\n",
       " ('fifteenth', 0.34639692306518555),\n",
       " ('asa', 0.34464627504348755),\n",
       " ('Ought', 0.3445321321487427),\n",
       " ('rejecting', 0.3435220420360565),\n",
       " ('refers', 0.3422543704509735),\n",
       " ('requiring', 0.34118330478668213),\n",
       " ('tbe', 0.33956560492515564),\n",
       " ('Should', 0.3389991521835327),\n",
       " ('authorizes', 0.33807122707366943),\n",
       " ('named.', 0.3374667763710022),\n",
       " ('2', 0.33452296257019043),\n",
       " ('fixing', 0.33439069986343384)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = congress_model.wv['woman'] - congress_model.wv['man']\n",
    "congress_model.wv.similar_by_vector(diff, topn = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# come back to rest: https://github.com/stephbuon/democracy-lab/blob/main/word-embeddings/workhorse-parallel-context-vectors.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyword1 = 'feminine'  # define the keyword you're looking for. you can change this variable as many times as you want.\n",
    "#enddate = 1950\n",
    "#########  after the first run, use this line to call the old data without generating it again\n",
    "#keyword_context = []\n",
    "#dates_found = []\n",
    "\n",
    "#for p in range(0, 18) :\n",
    "\n",
    "#    period1 = periodnames[p]\n",
    "#    print('working on ', period1)\n",
    "#    period_model = gensim.models.Word2Vec.load('model-' + str(period1)) # to load a saved model\n",
    "\n",
    "    ## analysis\n",
    "#    if keyword1 in period_model.wv.vocab:\n",
    "#        print('found ', keyword1)\n",
    "#        keyword_context_period = period_model.wv.most_similar(keyword1, topn = 5000) # extract the context of how women were talked about in that period\n",
    "#        keyword_context.append(keyword_context_period) # save the context of how women were talked about for later\n",
    "#        dates_found.append(period1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'woman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_context = []\n",
    "\n",
    "dir_path = '/users/sbuongiorno/diagnostics'\n",
    "    \n",
    "for fname in os.listdir(dir_path):\n",
    "    if '_model' in fname:\n",
    "        congress_model = gensim.models.Word2Vec.load(fname)\n",
    "        if keyword in congress_model.wv.vocab:\n",
    "            keyword_context_period = congress_model.wv.most_similar(keyword, topn = 1000)\n",
    "            keyword_context.append(keyword_context_period)\n",
    "        else: \n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mau', 0.7833964228630066),\n",
       " ('citizen', 0.7581620216369629),\n",
       " ('soldier', 0.7527076601982117),\n",
       " ('nian', 0.7463874816894531),\n",
       " ('man.', 0.7352272868156433),\n",
       " ('child', 0.7283610105514526),\n",
       " ('mian', 0.7250927090644836),\n",
       " ('foreigner', 0.7204998731613159),\n",
       " ('nan', 0.7189040184020996),\n",
       " ('lady', 0.7056132555007935),\n",
       " ('citizen.', 0.7028462290763855),\n",
       " ('mai', 0.696204662322998),\n",
       " ('man', 0.6869451999664307),\n",
       " ('mani', 0.6857932209968567),\n",
       " ('statesman', 0.6771718263626099)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_context[0][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mau', 'citizen', 'soldier', 'nian', 'man.']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[elem[0] for elem in keyword_context[0]][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7833964228630066,\n",
       " 0.7581620216369629,\n",
       " 0.7527076601982117,\n",
       " 0.7463874816894531,\n",
       " 0.7352272868156433]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[elem[1] for elem in keyword_context[0]][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe I want a df with 10 words per period and their scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unrelated: \n",
    "# you are too sensitive\n",
    "test = congressional_data[congressional_data['speech'].str.contains('you made me')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = congressional_data[congressional_data['speech'].str.contains('that never happened')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>year</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251740</th>\n",
       "      <td>The Senator from Vermont has fancied a case th...</td>\n",
       "      <td>1878</td>\n",
       "      <td>251740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028929</th>\n",
       "      <td>Perhaps it may. I will not undertake to say in...</td>\n",
       "      <td>1887</td>\n",
       "      <td>1028929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164184</th>\n",
       "      <td>Why bring this forthj ust on this particular o...</td>\n",
       "      <td>1888</td>\n",
       "      <td>1164184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425529</th>\n",
       "      <td>There are a great many things happening nowada...</td>\n",
       "      <td>1891</td>\n",
       "      <td>1425529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634636</th>\n",
       "      <td>I am much obliged to the Senator for his state...</td>\n",
       "      <td>1893</td>\n",
       "      <td>1634636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17318611</th>\n",
       "      <td>Mr. President. I rise to talk about a very imp...</td>\n",
       "      <td>2009</td>\n",
       "      <td>17318611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17341846</th>\n",
       "      <td>I thank the minority leader for allowing me to...</td>\n",
       "      <td>2010</td>\n",
       "      <td>17341846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17344143</th>\n",
       "      <td>sylvania. I thank the chairman for yielding. I...</td>\n",
       "      <td>2010</td>\n",
       "      <td>17344143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17391401</th>\n",
       "      <td>Madam President. I thank my new colleague from...</td>\n",
       "      <td>2010</td>\n",
       "      <td>17391401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17394008</th>\n",
       "      <td>I thank the Chair. I assure my colleagues. I w...</td>\n",
       "      <td>2010</td>\n",
       "      <td>17394008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     speech  year     index\n",
       "251740    The Senator from Vermont has fancied a case th...  1878    251740\n",
       "1028929   Perhaps it may. I will not undertake to say in...  1887   1028929\n",
       "1164184   Why bring this forthj ust on this particular o...  1888   1164184\n",
       "1425529   There are a great many things happening nowada...  1891   1425529\n",
       "1634636   I am much obliged to the Senator for his state...  1893   1634636\n",
       "...                                                     ...   ...       ...\n",
       "17318611  Mr. President. I rise to talk about a very imp...  2009  17318611\n",
       "17341846  I thank the minority leader for allowing me to...  2010  17341846\n",
       "17344143  sylvania. I thank the chairman for yielding. I...  2010  17344143\n",
       "17391401  Madam President. I thank my new colleague from...  2010  17391401\n",
       "17394008  I thank the Chair. I assure my colleagues. I w...  2010  17394008\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = congressional_data[congressional_data['speech'].str.contains('I always tell the truth')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>year</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2560612</th>\n",
       "      <td>I always tell the truth. here and everywhere. ...</td>\n",
       "      <td>1904</td>\n",
       "      <td>2560612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4752200</th>\n",
       "      <td>I always tell the truth. and there was so much...</td>\n",
       "      <td>1919</td>\n",
       "      <td>4752200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7016836</th>\n",
       "      <td>I thank the Senator from Nevada. he knows that...</td>\n",
       "      <td>1935</td>\n",
       "      <td>7016836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11717223</th>\n",
       "      <td>Mr. Speaker. since my election to Congress in ...</td>\n",
       "      <td>1968</td>\n",
       "      <td>11717223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     speech  year     index\n",
       "2560612   I always tell the truth. here and everywhere. ...  1904   2560612\n",
       "4752200   I always tell the truth. and there was so much...  1919   4752200\n",
       "7016836   I thank the Senator from Nevada. he knows that...  1935   7016836\n",
       "11717223  Mr. Speaker. since my election to Congress in ...  1968  11717223"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
