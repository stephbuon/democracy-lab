{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_043.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_044.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_045.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_046.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_047.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_048.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_049.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_050.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_051.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_052.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_053.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_054.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_055.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_056.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_057.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_058.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_059.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_060.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_061.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_062.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_063.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_064.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_065.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_066.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_067.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_068.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_069.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_070.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_071.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_072.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_073.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_074.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_075.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_076.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_077.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_078.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_079.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_080.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_081.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_082.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_083.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_084.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_085.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_086.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_087.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_088.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_089.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_090.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_091.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_092.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_093.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_094.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_095.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_096.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_097.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_098.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_099.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_100.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_101.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_102.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_103.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_104.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_105.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_106.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_107.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_108.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_109.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_110.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_111.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_043.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_044.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_045.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_046.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_047.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_048.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_049.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_050.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_051.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_052.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_053.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_054.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_055.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_056.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_057.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_058.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_059.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_060.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_061.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_062.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_063.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_064.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_065.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_066.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_067.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_068.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_069.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_070.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_071.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_072.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_073.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_074.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_075.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_076.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_077.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_078.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_079.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_080.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_081.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_082.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_083.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_084.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_085.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_086.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_087.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_088.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_089.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_090.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_091.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_092.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_093.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_094.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_095.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_096.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_097.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_098.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_099.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_100.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_101.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_102.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_103.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_104.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_105.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_106.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_107.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_108.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_109.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_110.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_111.txt...\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "def read_speeches():\n",
    "    all_speech_files = glob.glob('/scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_*.txt')\n",
    "    CONGRESS_MIN_THRESHOLD = 1\n",
    "    CONGRESS_MAX_THRESHOLD = 115\n",
    "    \n",
    "    speech_files = []\n",
    "    \n",
    "    for fn in all_speech_files:\n",
    "        number = int(fn.rsplit('_', 1)[-1].split('.')[0])\n",
    "        \n",
    "        if CONGRESS_MIN_THRESHOLD <= number <= CONGRESS_MAX_THRESHOLD:\n",
    "            speech_files.append(fn)\n",
    "            speech_files.sort()\n",
    "    return speech_files\n",
    "\n",
    "def read_descriptions():\n",
    "    all_description_files = glob.glob('/scratch/group/oit_research_data/stanford_congress/hein-bound/descr_*.txt')\n",
    "    CONGRESS_MIN_THRESHOLD = 1\n",
    "    CONGRESS_MAX_THRESHOLD = 115\n",
    "    \n",
    "    description_files = []\n",
    "    \n",
    "    for fn in all_description_files:\n",
    "        number = int(fn.rsplit('_', 1)[-1].split('.')[0])\n",
    "        \n",
    "        if CONGRESS_MIN_THRESHOLD <= number <= CONGRESS_MAX_THRESHOLD:\n",
    "            description_files.append(fn)\n",
    "            description_files.sort()\n",
    "    return description_files\n",
    "        \n",
    "def reader(fn):\n",
    "    print(f'Reading {fn}...')\n",
    "    return pd.read_csv(fn, sep='|', encoding=\"ISO-8859-1\", error_bad_lines=False, warn_bad_lines=False, quoting=csv.QUOTE_NONE)\n",
    "\n",
    "def clean_data(all_data):\n",
    "    all_data = all_data.drop(['chamber', 'speech_id', 'number_within_file', 'speaker', 'first_name'], 1)\n",
    "    all_data = all_data.drop(['last_name', 'state', 'gender', 'line_start', 'line_end', 'file', 'char_count', 'word_count'], 1)\n",
    "    all_data['date']=pd.to_datetime(all_data['date'],format='%Y%m%d')\n",
    "    all_data['year'] = pd.to_datetime(all_data['date']).dt.year\n",
    "    all_data['5yrperiod'] = np.floor(all_data['year'] / 5) * 5 # round each year to the nearest 5 -- by dividing by 5 and \"flooring\" to the lowest integer\n",
    "    all_data = all_data.drop(['date', '5yrperiod'], 1)\n",
    "    all_data['index'] = np.arange(len(all_data)) # create an 'index' column\n",
    "    return all_data\n",
    "    \n",
    "def import_congressional_data(*args, **kwargs):\n",
    "    cd = kwargs.get('clean_data', None)\n",
    "    speech_files = read_speeches()\n",
    "    description_files = read_descriptions()\n",
    "    \n",
    "    speeches_df = pd.concat((reader(fn) for fn in speech_files))\n",
    "    speeches_df.dropna(how='any', inplace=True)\n",
    "    \n",
    "    description_df = pd.concat((reader(fn) for fn in description_files))\n",
    "    \n",
    "    all_data = pd.merge(speeches_df, description_df, on = 'speech_id')\n",
    "    all_data.fillna(0, inplace=True)\n",
    "    \n",
    "    if cd == True:\n",
    "        all_data = clean_data(all_data)\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "congressional_data = import_congressional_data(clean_data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "from varname import nameof\n",
    "\n",
    "def set_dir(data): \n",
    "    path = os.getcwd()\n",
    "    current_folder = os.path.basename(path)\n",
    "    target_folder = nameof(data) + '_subsets'\n",
    "\n",
    "    if current_folder != target_folder:\n",
    "        os.makedirs(target_folder)\n",
    "        os.chdir(target_folder)\n",
    "        \n",
    "def interval_subset(data, col_name, start, end, intv):\n",
    "    set_dir(data)\n",
    "    \n",
    "    start = start\n",
    "    end = end\n",
    "\n",
    "    while start <= end:\n",
    "        start = start + intv\n",
    "        subset = data[(data[col_name] >= start - intv) & (data[col_name] <= start - 1)]\n",
    "        \n",
    "        descr = str(subset[col_name].iloc[0])\n",
    "        descr_2 = str(subset[col_name]. iloc[-1])\n",
    "        \n",
    "        file_name = \"stanford_congressional_records_\" + descr + \"_\" + descr_2\n",
    "        \n",
    "        subset.to_csv(file_name + \".csv\", index = False)\n",
    "        \n",
    "interval_subset(congressional_data, 'year', 1870, 2010, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue, cpu_count\n",
    "\n",
    "def parallelize_operation(df, function, n_cores = n):\n",
    "    split_df = np.array_split(df, n_cores)\n",
    "    pool = Pool(n)\n",
    "    df = pd.concat(pool.map(function, split_df))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://towardsdatascience.com/tokenize-text-columns-into-sentences-in-pandas-2c08bc1ca790\n",
    "\n",
    "def sentence_split(df):\n",
    "    \n",
    "     pd.concat([Series(row['var2'], row['var1'].split(','))              \n",
    "                    for _, row in a.iterrows()]).reset_index()\n",
    "    \n",
    "    \n",
    "    s = df['speech'].str.split('.').apply(pd.Series,1).stack()\n",
    "    s.index = s.index.droplevel(-1) # to line up with df's index\n",
    "    s.name = 'sentence' # needs a name to join\n",
    "\n",
    "    del df['speech']\n",
    "    df = df.join(s)\n",
    "    del df['index']\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-9-7fa92082d5b4>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-7fa92082d5b4>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    sentences_df = parallelize_operation(period_data, structure_me3) #  split speech into sentences\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gensim\n",
    "\n",
    "export_gensim_model('/users/sbuongiorno/triples_in_hansard/ft_14351103', )\n",
    "\n",
    "def export_congressional_gensim_models(dir_path):\n",
    "    file_names = []\n",
    "    \n",
    "    for fname in os.listdir(dir_path):\n",
    "        file_names.append(fname)\n",
    "        \n",
    "    for fname in file_names:\n",
    "        imported_data = pd.read_csv(fname)\n",
    "        \n",
    "        sentences_df = parallelize_operation(imported_data, #structure_me3)\n",
    "        \n",
    "        \n",
    "        period_model = gensim.models.Word2Vec(sentences = )\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#for period1 in periodnames:\n",
    "    \n",
    "    # just the data in the period in question, then clean it\n",
    "    #period_data = all_data[all_data['5yrperiod'] == period1]\n",
    "\n",
    "    sentences_df = parallelize_operation(period_data, structure_me3) #  split speech into sentences\n",
    "    sentences_df2 = split_sentences3(sentences_df) # split sentences into words\n",
    "    sentences_df3 = cleanup(sentences_df2) # cleanup punctuation and empty lines\n",
    "    \n",
    "    # make a gensim model for that data\n",
    "    period_model = gensim.models.Word2Vec( \n",
    "        sentences = sentences_df3['sentence'],\n",
    "        workers= n,\n",
    "        iter = 15,\n",
    "        min_count = 20, \n",
    "        size = 100)  \n",
    "    \n",
    "    # save the model with the name of the period\n",
    "    period_model.save('model-' + str(period1)) \n",
    "    \n",
    "    # load model for each 5 yr period - one period per cycle of the for loop\n",
    "    #period_model = gensim.models.Word2Vec.load('model-' + str(period1)) # to load a saved model\n",
    "\n",
    "    # append each period to a larger model of all congress\n",
    "    if period1 == periodnames[0]:\n",
    "        congress_model = period_model # for the first time, save period_model as congress model\n",
    "    else:    \n",
    "        congress_model.build_vocab(sentences_df3['sentence'], # after the first period, add new period data to the congress model\n",
    "                               update = True)\n",
    "        congress_model.train(sentences_df3['sentence'], total_examples=period_model.corpus_count, epochs=period_model.epochs) \n",
    "\n",
    "    # store the model with the name of the period\n",
    "    congress_model.save('congress_model-' + str(startdate) + '-' + str(enddate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
